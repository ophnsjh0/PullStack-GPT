{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: 내 이름은 정훈입니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'안녕하세요 정훈님! 만나서 반갑습니다. 저는 인공지능입니다. 무엇을 도와드릴까요?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain.prompts.few_shot import FewShotPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "# from langchain.callbacks import StreamingStdOutCallbackHandler, get_openai_callback\n",
    "# from langchain.prompts import example_selector\n",
    "# from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "# from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "# from langchain.globals import set_llm_cache, set_debug\n",
    "# from langchain.cache import InMemoryCache, SQLiteCache\n",
    "# from langchain.llms.openai import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory, ConversationSummaryMemory, ConversationSummaryBufferMemory, ConversationKGMemory\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, load_prompt, MessagesPlaceholder\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI talking to a human\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.predict(question=\"내 이름은 정훈입니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: 내 이름은 정훈입니다.\n",
      "AI: 안녕하세요 정훈님! 만나서 반갑습니다. 저는 인공지능입니다. 무엇을 도와드릴까요?\n",
      "Human: 나는 용인에 살아요.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'용인은 경기도에 위치한 아름다운 도시입니다. 어떤 도움이 필요하신가요? 관광지 추천이나 현지 정보, 교통 정보 등을 알려드릴 수 있습니다.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"나는 용인에 살아요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "System: The human introduces themselves as 정훈. The AI greets 정훈 and introduces itself as an artificial intelligence, asking how it can assist.\n",
      "Human: 나는 용인에 살아요.\n",
      "AI: 용인은 경기도에 위치한 아름다운 도시입니다. 어떤 도움이 필요하신가요? 관광지 추천이나 현지 정보, 교통 정보 등을 알려드릴 수 있습니다.\n",
      "Human: 내 이름이 뭔가요?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'당신의 이름은 정훈입니다.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"내 이름이 뭔가요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "System: The human introduces themselves as 정훈 and the AI greets 정훈, introducing itself as an artificial intelligence and asking how it can assist. 정훈 responds by saying they live in Yongin.\n",
      "AI: 용인은 경기도에 위치한 아름다운 도시입니다. 어떤 도움이 필요하신가요? 관광지 추천이나 현지 정보, 교통 정보 등을 알려드릴 수 있습니다.\n",
      "Human: 내 이름이 뭔가요?\n",
      "AI: 당신의 이름은 정훈입니다.\n",
      "Human: 나를 어떻게 도와줄수 있나요?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저는 여러 가지 방법으로 도움을 드릴 수 있습니다. 예를 들어, 여행 관련 정보를 제공하거나 교통 정보를 알려드릴 수 있습니다. 또한 일상 생활에서 필요한 정보나 질문에 대한 답변을 제공할 수도 있습니다. 무엇을 도와드릴까요?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"나를 어떻게 도와줄수 있나요?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
