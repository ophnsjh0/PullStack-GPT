{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to human\n",
      "    \n",
      "    \n",
      "    Human: 내 이름은 정훈입니다.\n",
      "    You: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'안녕하세요 정훈님! 저는 여러분을 도와드리는 인공지능입니다. 무엇을 도와드릴까요?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain.prompts.few_shot import FewShotPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "# from langchain.callbacks import StreamingStdOutCallbackHandler, get_openai_callback\n",
    "# from langchain.prompts import example_selector\n",
    "# from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "# from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "# from langchain.globals import set_llm_cache, set_debug\n",
    "# from langchain.cache import InMemoryCache, SQLiteCache\n",
    "# from langchain.llms.openai import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory, ConversationSummaryMemory, ConversationSummaryBufferMemory, ConversationKGMemory\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, load_prompt\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    memory_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "    You are a helpful AI talking to human\n",
    "    \n",
    "    {chat_history}\n",
    "    Human: {question}\n",
    "    You: \n",
    "\"\"\"\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=PromptTemplate.from_template(template),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.predict(question=\"내 이름은 정훈입니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to human\n",
      "    \n",
      "    Human: 내 이름은 정훈입니다.\n",
      "AI: 안녕하세요 정훈님! 저는 여러분을 도와드리는 인공지능입니다. 무엇을 도와드릴까요?\n",
      "    Human: 나는 용인에 살아요.\n",
      "    You: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'용인은 경기도에 위치한 도시로 알고 있습니다. 용인에서 어떤 도움이 필요하신가요?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"나는 용인에 살아요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to human\n",
      "    \n",
      "    System: The human introduces themselves as 정훈.\n",
      "AI: 안녕하세요 정훈님! 저는 여러분을 도와드리는 인공지능입니다. 무엇을 도와드릴까요?\n",
      "Human: 나는 용인에 살아요.\n",
      "AI: 용인은 경기도에 위치한 도시로 알고 있습니다. 용인에서 어떤 도움이 필요하신가요?\n",
      "    Human: 내 이름이 뭔가요?\n",
      "    You: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'당신의 이름은 정훈입니다.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"내 이름이 뭔가요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to human\n",
      "    \n",
      "    System: The human introduces themselves as 정훈. The AI greets 정훈 and introduces itself as an artificial intelligence that is here to assist. The AI asks how it can help 정훈.\n",
      "Human: 나는 용인에 살아요.\n",
      "AI: 용인은 경기도에 위치한 도시로 알고 있습니다. 용인에서 어떤 도움이 필요하신가요?\n",
      "Human: 내 이름이 뭔가요?\n",
      "AI: 당신의 이름은 정훈입니다.\n",
      "    Human: 나를 어떻게 도와줄수 있나요?\n",
      "    You: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저는 여러 가지 방법으로 도움을 드릴 수 있습니다. 예를 들어, 여행 관련 정보나 날씨 정보를 제공하거나, 일정 관리나 알람 설정을 도와드릴 수 있습니다. 또한, 교육적인 내용이나 일상 생활에서 필요한 정보를 찾아드리거나, 간단한 질문에 대한 답변을 제공할 수도 있습니다. 무엇을 도와드릴까요?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"나를 어떻게 도와줄수 있나요?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
